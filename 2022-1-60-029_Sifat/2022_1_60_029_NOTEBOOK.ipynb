{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to drive"
      ],
      "metadata": {
        "id": "-D2_V6ujO3X8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeplpGwpOjtz"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab Exam:\n",
        "# SOLVE = 1\n",
        "# Step 1 : Reading & Analyzing Cleaned Comments"
      ],
      "metadata": {
        "id": "nYrc-kUaU0Gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/477_lab_exam/cleaned_comments.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "print(\"Dataset Shape (rows, cols):\", df.shape)\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "display(df.head())\n",
        "\n",
        "print(\"\\nDataset Info:\")\n",
        "df.info()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vjLgft-fO2j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Step 2 : Handle rows consistently\n",
        " Drop duplicate rows (if any)"
      ],
      "metadata": {
        "id": "cf-rPlxJVFlq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop_duplicates()\n",
        "\n",
        "# Handle missing values → drop rows with all NaN, fill others with empty string\n",
        "df = df.dropna(how=\"all\")\n",
        "df = df.fillna(\"\")\n",
        "\n",
        "print(\"\\nAfter cleaning:\")\n",
        "print(\"Shape:\", df.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "10z_-hXNUfiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Basic Analysis\n",
        "- Number of comments\n",
        "- Average length of comments\n",
        "- Show 5 longest comments"
      ],
      "metadata": {
        "id": "gaj_op5UVYNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTotal number of comments:\", len(df))\n",
        "\n",
        "\n",
        "df[\"comment_length\"] = df.iloc[:,0].astype(str).apply(len)\n",
        "print(\"Average comment length:\", df[\"comment_length\"].mean())\n",
        "\n",
        "\n",
        "print(\"\\nTop 5 Longest Comments:\")\n",
        "display(df.sort_values(\"comment_length\", ascending=False).head())\n",
        "\n",
        "\n",
        "print(\"\\nDescriptive Stats:\")\n",
        "display(df[\"comment_length\"].describe())\n"
      ],
      "metadata": {
        "id": "1_uo4vo-UsyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SOLVE = 2"
      ],
      "metadata": {
        "id": "06cpOY6QV8Kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: (Optional) Install packages for extra text processing/visuals.\n",
        "# If you don't need lemmatization or wordcloud, you can skip this cell.\n",
        "!pip install -q nltk\n",
        "\n"
      ],
      "metadata": {
        "id": "LiEt9MtPWAM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: imports and helper functions\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# basic text cleaning function\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        text = str(text)\n",
        "    text = text.lower()\n",
        "    # remove urls, mentions, hashtags\n",
        "    text = re.sub(r'http\\S+|www\\.\\S+', ' ', text)\n",
        "    text = re.sub(r'@\\w+|#\\w+', ' ', text)\n",
        "    # keep alphanumerics and simple punctuation, replace others with space\n",
        "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
        "    # collapse multiple spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "Pqsz94paXDn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Load CSV and auto-detect likely text column\n",
        "file_path = \"/content/drive/MyDrive/477_lab_exam/cleaned_comments.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(\"Original shape:\", df.shape)\n",
        "display(df.head(5))\n",
        "\n",
        "# try to auto-detect comment/text column by common names\n",
        "possible_names = ['comment', 'comments', 'text', 'cleaned_comment', 'cleaned_comments', 'message', 'content']\n",
        "text_col = None\n",
        "for name in possible_names:\n",
        "    if name in df.columns.str.lower():\n",
        "        # keep matching original case\n",
        "        text_col = df.columns[df.columns.str.lower() == name][0]\n",
        "        break\n",
        "\n",
        "# If not found, pick the first column (common in student datasets)\n",
        "if text_col is None:\n",
        "    text_col = df.columns[0]\n",
        "    print(f\"Did not find a standard text column. Using first column: '{text_col}'\")\n",
        "else:\n",
        "    print(f\"Using detected text column: '{text_col}'\")\n",
        "\n",
        "# Ensure it's string\n",
        "df[text_col] = df[text_col].astype(str)\n"
      ],
      "metadata": {
        "id": "iZDqwA6qXINw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Drop rows that are totally empty, fill partial NaNs, and drop exact duplicates\n",
        "# Drop rows where the chosen text column is empty / whitespace only\n",
        "df[text_col] = df[text_col].apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
        "initial_shape = df.shape\n",
        "\n",
        "# drop rows where text is empty\n",
        "df = df[~df[text_col].isin(['', 'nan', 'None', None])]\n",
        "\n",
        "# drop exact duplicate rows (all columns identical)\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "print(\"Initial shape:\", initial_shape)\n",
        "print(\"After dropping empty/duplicate rows:\", df.shape)\n",
        "\n",
        "# preview\n",
        "display(df.head(8))\n"
      ],
      "metadata": {
        "id": "QtbsMxxgXKXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Apply clean_text to create a preprocessed column for vectorization\n",
        "df['cleaned_text'] = df[text_col].apply(clean_text)\n",
        "\n",
        "# If any rows became empty after cleaning (rare), drop them\n",
        "df = df[df['cleaned_text'].str.strip() != '']\n",
        "\n",
        "print(\"After cleaning, sample cleaned_text:\")\n",
        "display(df[['cleaned_text']].head(8))\n"
      ],
      "metadata": {
        "id": "fsHEMM9aXNl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: TF-IDF vectorization\n",
        "# If you ran lemmatization cell, uncomment the following line; otherwise use cleaned_text:\n",
        "# use_col = 'cleaned_text_lem'\n",
        "\n",
        "# If you didn't run lemmatize, set:\n",
        "use_col = 'cleaned_text' if 'cleaned_text_lem' not in df.columns else 'cleaned_text_lem'\n",
        "\n",
        "texts = df[use_col].tolist()\n",
        "\n",
        "# TF-IDF parameters -- tuned for exam: highlight important words and reduce noise\n",
        "vectorizer = TfidfVectorizer(\n",
        "    stop_words='english',   # remove common english stop words\n",
        "    max_df=0.95,            # ignore very common words in corpus\n",
        "    min_df=2,               # ignore words that appear in only 1 document\n",
        "    max_features=15000,     # limit vocabulary size (adjust if you have tiny dataset)\n",
        "    ngram_range=(1,2)       # use unigrams and bigrams (helps capture short phrases)\n",
        ")\n",
        "X = vectorizer.fit_transform(texts)\n",
        "print(\"TF-IDF matrix shape:\", X.shape)\n"
      ],
      "metadata": {
        "id": "i2mbiwjUXQs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Clustering into exactly 3 groups\n",
        "n_clusters = 3\n",
        "num_docs = X.shape[0]\n",
        "\n",
        "# For very large datasets, MiniBatchKMeans is faster and memory-friendly\n",
        "if num_docs > 20000:\n",
        "    print(\"Large dataset detected — using MiniBatchKMeans for speed/memory.\")\n",
        "    kmeans = MiniBatchKMeans(n_clusters=n_clusters, random_state=42, batch_size=1000, n_init=10)\n",
        "else:\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "\n",
        "labels = kmeans.fit_predict(X)\n",
        "df['Group'] = labels  # each comment gets exactly one group label: 0,1,2\n",
        "\n",
        "print(\"Cluster assignment complete.\")\n",
        "print(\"Group counts:\")\n",
        "print(df['Group'].value_counts().sort_index())\n"
      ],
      "metadata": {
        "id": "oYBKmOGrXR2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Save results with Group column\n",
        "output_path = \"/content/drive/MyDrive/477_lab_exam/grouped_comments.csv\"\n",
        "df.to_csv(output_path, index=False)\n",
        "print(\"Saved grouped file to:\", output_path)\n"
      ],
      "metadata": {
        "id": "yNyJC5VpXax5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: Inspect clusters: sample comments and top words per cluster\n",
        "display(df[[text_col, use_col, 'Group']].sample(12, random_state=42))\n",
        "\n",
        "# Show top keywords per cluster (based on cluster centers)\n",
        "terms = vectorizer.get_feature_names_out()\n",
        "order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
        "\n",
        "for i in range(n_clusters):\n",
        "    top_terms = [terms[ind] for ind in order_centroids[i, :15] if ind < len(terms)]\n",
        "    print(f\"\\nTop words for Group {i} (top 15):\")\n",
        "    print(\", \".join(top_terms))\n",
        "\n",
        "# Show 5 example comments per group\n",
        "for i in range(n_clusters):\n",
        "    print(f\"\\n--- Examples from Group {i} ---\")\n",
        "    display(df[df['Group'] == i][[text_col]].head(5))\n"
      ],
      "metadata": {
        "id": "72m3XrcfXdrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: 2D visualization (TruncatedSVD for sparse TF-IDF)\n",
        "svd = TruncatedSVD(n_components=2, random_state=42)\n",
        "X2 = svd.fit_transform(X)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "scatter = plt.scatter(X2[:,0], X2[:,1], c=df['Group'], alpha=0.6)\n",
        "plt.title(\"2D projection of comments (TruncatedSVD) — colored by Group\")\n",
        "plt.xlabel(\"Component 1\")\n",
        "plt.ylabel(\"Component 2\")\n",
        "plt.colorbar(scatter, ticks=[0,1,2], label='Group')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MzkRSSgVXez4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SOLVE = 3"
      ],
      "metadata": {
        "id": "Coa8yj9eYQQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 13: Prepare environment and basic checks (run after your previous clustering cells)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Ensure required variables exist (these come from previous pipeline)\n",
        "assert 'df' in globals(), \"Run earlier cells first so 'df' exists.\"\n",
        "assert 'vectorizer' in globals(), \"Run TF-IDF cell first to create 'vectorizer'.\"\n",
        "assert 'kmeans' in globals(), \"Run clustering cell first to create 'kmeans'.\"\n",
        "assert 'use_col' in globals(), \"Ensure 'use_col' points to your cleaned-text column.\"\n",
        "\n",
        "terms = vectorizer.get_feature_names_out()\n",
        "n_clusters = kmeans.n_clusters if hasattr(kmeans, 'n_clusters') else 3\n",
        "\n",
        "print(\"Ready. Number of clusters:\", n_clusters)\n",
        "print(\"TF-IDF vocabulary size:\", len(terms))\n"
      ],
      "metadata": {
        "id": "YWmK0sNsYTs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 14: Compute per-cluster combined score and choose the top keyword\n",
        "count_vectorizer = CountVectorizer(vocabulary=terms)  # align counts to TF-IDF terms\n",
        "\n",
        "def normalize_array(a):\n",
        "    a = a.astype(float)\n",
        "    a_min, a_max = a.min(), a.max()\n",
        "    if a_max == a_min:\n",
        "        # If all identical, return zeros (or ones) — use zeros so counts don't dominate\n",
        "        return np.zeros_like(a)\n",
        "    return (a - a_min) / (a_max - a_min)\n",
        "\n",
        "group_infos = []\n",
        "\n",
        "for i in range(n_clusters):\n",
        "    # indices & texts in this cluster\n",
        "    docs_idx = df[df['Group'] == i].index\n",
        "    cluster_texts = df.loc[docs_idx, use_col].astype(str).tolist()\n",
        "    if len(cluster_texts) == 0:\n",
        "        group_infos.append({\n",
        "            'group': i,\n",
        "            'chosen_word': None,\n",
        "            'note': 'empty_cluster',\n",
        "            'top_tfidf_word': None,\n",
        "            'top_count_word': None\n",
        "        })\n",
        "        continue\n",
        "\n",
        "    # 1) centroid weights (TF-IDF importance for cluster)\n",
        "    centroid = kmeans.cluster_centers_[i]  # shape (n_terms,)\n",
        "    # 2) raw term counts in the cluster (using same vocab)\n",
        "    term_count_matrix = count_vectorizer.transform(cluster_texts)  # docs x vocab\n",
        "    term_counts = np.asarray(term_count_matrix.sum(axis=0)).ravel()  # shape (n_terms,)\n",
        "\n",
        "    # normalize both signals to [0,1]\n",
        "    centroid_norm = normalize_array(centroid)\n",
        "    counts_norm = normalize_array(term_counts)\n",
        "\n",
        "    # combined score (equal weight to both signals)\n",
        "    combined_score = centroid_norm + counts_norm\n",
        "\n",
        "    # pick best index\n",
        "    best_idx = int(np.argmax(combined_score))\n",
        "    chosen_word = terms[best_idx]\n",
        "\n",
        "    # for transparency collect also the top pure-tfidf and top pure-count words\n",
        "    top_tfidf_idx = int(np.argmax(centroid))\n",
        "    top_count_idx = int(np.argmax(term_counts))\n",
        "    top_tfidf_word = terms[top_tfidf_idx]\n",
        "    top_count_word = terms[top_count_idx]\n",
        "\n",
        "    group_infos.append({\n",
        "        'group': i,\n",
        "        'chosen_word': chosen_word,\n",
        "        'chosen_score': float(combined_score[best_idx]),\n",
        "        'top_tfidf_word': top_tfidf_word,\n",
        "        'top_tfidf_weight': float(centroid[top_tfidf_idx]),\n",
        "        'top_count_word': top_count_word,\n",
        "        'top_count': int(term_counts[top_count_idx])\n",
        "    })\n",
        "\n",
        "# Create DataFrame of diagnostics\n",
        "group_df = pd.DataFrame(group_infos).sort_values('group').reset_index(drop=True)\n",
        "display(group_df)\n"
      ],
      "metadata": {
        "id": "xJQokpaYZ1X_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 15: Make the final \"Group number\" ↔ \"Chosen keyword\" table, add a nicer Label, and save\n",
        "label_table = group_df[['group', 'chosen_word']].copy()\n",
        "label_table.columns = ['Group', 'Chosen_Keyword']\n",
        "\n",
        "# Make a presentable Label (Title Case) and handle missing picks\n",
        "label_table['Label'] = label_table['Chosen_Keyword'].fillna('Unknown').astype(str).str.replace('_',' ').str.title()\n",
        "\n",
        "# Final 2-column table (Group number, Chosen keyword label)\n",
        "final_table = label_table[['Group', 'Label']].copy()\n",
        "\n",
        "# Display nicely\n",
        "display(final_table.style.set_caption(\"Group → Representative Keyword\").format({'Group': '{:.0f}'}))\n",
        "\n",
        "# Save to Drive\n",
        "output_labels_path = \"/content/drive/MyDrive/477_lab_exam/group_labels.csv\"\n",
        "final_table.to_csv(output_labels_path, index=False)\n",
        "print(\"Saved group labels to:\", output_labels_path)\n"
      ],
      "metadata": {
        "id": "6AyRVK4YZ7iW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 16: Map chosen labels back onto df and show quick examples per labeled group\n",
        "label_map = dict(zip(final_table['Group'], final_table['Label']))\n",
        "df['Group_Label'] = df['Group'].map(label_map)\n",
        "\n",
        "print(\"Counts per labeled group:\")\n",
        "display(df['Group_Label'].value_counts().rename_axis('Label').reset_index(name='Count'))\n",
        "\n",
        "# Show up to 10 sample comments per labeled group with the label visible\n",
        "for grp in sorted(df['Group'].unique()):\n",
        "    lbl = label_map.get(grp, f\"Group {grp}\")\n",
        "    print(f\"\\n=== Samples for {lbl} (Group {grp}) ===\")\n",
        "    display(df[df['Group'] == grp][[use_col]].head(10))\n"
      ],
      "metadata": {
        "id": "ds4hJyRBaBBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 17: Install wordcloud package (if not already installed)\n",
        "!pip install -q wordcloud"
      ],
      "metadata": {
        "id": "TZTM6WuPagI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 18: Plot top 10 TF-IDF words for each group\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "terms = vectorizer.get_feature_names_out()\n",
        "order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
        "\n",
        "for i in range(n_clusters):\n",
        "    top_indices = order_centroids[i, :10]\n",
        "    top_terms = [terms[ind] for ind in top_indices]\n",
        "    top_weights = [kmeans.cluster_centers_[i, ind] for ind in top_indices]\n",
        "\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.barh(top_terms[::-1], top_weights[::-1], color=\"skyblue\")\n",
        "    plt.title(f\"Group {i} — Top 10 Words (TF-IDF weight)\")\n",
        "    plt.xlabel(\"TF-IDF Weight\")\n",
        "    plt.ylabel(\"Words\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "x0xKBVtGawqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 19: WordCloud visualization for each group\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "for i in range(n_clusters):\n",
        "    cluster_texts = df[df['Group'] == i][use_col].astype(str)\n",
        "    combined_text = \" \".join(cluster_texts)\n",
        "\n",
        "    if combined_text.strip() == \"\":\n",
        "        print(f\"Group {i} is empty, skipping wordcloud.\")\n",
        "        continue\n",
        "\n",
        "    wordcloud = WordCloud(\n",
        "        width=800, height=400,\n",
        "        background_color=\"white\",\n",
        "        colormap=\"viridis\",\n",
        "        max_words=100\n",
        "    ).generate(combined_text)\n",
        "\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"WordCloud for Group {i}\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "0yISDjW1aytP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SOLVE = 4"
      ],
      "metadata": {
        "id": "fBDPDZk7a5m2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install NLTK and required packages\n",
        "!pip install -q nltk\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# NLTK for sentiment analysis\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n"
      ],
      "metadata": {
        "id": "ea_B8VXNa5KF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your cleaned comments CSV (or the labeled one from Q3)\n",
        "file_path = \"/content/drive/MyDrive/477_lab_exam/grouped_comments.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Check columns\n",
        "print(\"Dataset columns:\", df.columns)\n",
        "print(\"First 5 rows:\")\n",
        "display(df.head())\n",
        "\n",
        "# We'll use 'cleaned_text' column for sentiment\n",
        "use_col = 'cleaned_text'\n"
      ],
      "metadata": {
        "id": "MwJyW8l1cLgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize VADER Sentiment Analyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Example: analyze a single comment\n",
        "example_text = df[use_col].iloc[0]\n",
        "sia.polarity_scores(example_text)\n"
      ],
      "metadata": {
        "id": "bWLdvQGxcS30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to map VADER compound score to sentiment label\n",
        "def get_sentiment_label(text):\n",
        "    score = sia.polarity_scores(text)['compound']\n",
        "    if score >= 0.05:\n",
        "        return 'Positive'\n",
        "    elif score <= -0.05:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "# Apply sentiment analysis\n",
        "df['Sentiment'] = df[use_col].apply(get_sentiment_label)\n",
        "\n",
        "# Quick stats\n",
        "print(\"Sentiment distribution:\")\n",
        "display(df['Sentiment'].value_counts())\n"
      ],
      "metadata": {
        "id": "E-Ah5npEcVHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot sentiment distribution\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.countplot(x='Sentiment', data=df, order=['Positive', 'Neutral', 'Negative'], palette='pastel')\n",
        "plt.title(\"Sentiment Distribution of Comments\")\n",
        "plt.ylabel(\"Number of Comments\")\n",
        "plt.xlabel(\"Sentiment\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Ns0_gE7acYg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# How sentiments distribute across groups\n",
        "sentiment_group = df.groupby(['Group', 'Sentiment']).size().reset_index(name='Count')\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.barplot(x='Group', y='Count', hue='Sentiment', data=sentiment_group, palette='Set2')\n",
        "plt.title(\"Sentiment Distribution Across Groups\")\n",
        "plt.ylabel(\"Number of Comments\")\n",
        "plt.xlabel(\"Group\")\n",
        "plt.legend(title=\"Sentiment\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZCvE4d-cccGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save final dataset with Group, Label, Sentiment\n",
        "output_path_sentiment = \"/content/drive/MyDrive/477_lab_exam/grouped_comments_sentiment.csv\"\n",
        "df.to_csv(output_path_sentiment, index=False)\n",
        "print(f\"✅ Saved dataset with sentiment labels: {output_path_sentiment}\")\n"
      ],
      "metadata": {
        "id": "lPUxaWmUc06k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SOLVE = 5"
      ],
      "metadata": {
        "id": "NGpu3p5Pc6-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 5: Visualize Group Distribution\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/477_lab_exam/grouped_comments_sentiment.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "print(\"Groups present in dataset:\", df['Group'].unique())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7K1P835_c88s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "group_counts = df['Group'].value_counts().sort_index()\n",
        "print(\"Number of comments per group:\")\n",
        "display(group_counts)\n",
        "\n"
      ],
      "metadata": {
        "id": "CRhnplxTeHqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.barplot(x=group_counts.index, y=group_counts.values, palette='pastel')\n",
        "\n",
        "\n",
        "for i, count in enumerate(group_counts.values):\n",
        "    plt.text(i, count + max(group_counts.values)*0.01, str(count), ha='center', va='bottom', fontsize=12)\n",
        "\n",
        "plt.title(\"Distribution of Comments Across Groups\", fontsize=14)\n",
        "plt.xlabel(\"Group\", fontsize=12)\n",
        "plt.ylabel(\"Number of Comments\", fontsize=12)\n",
        "plt.xticks(ticks=[0,1,2], labels=[f\"Group {i}\" for i in group_counts.index])\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "\n"
      ],
      "metadata": {
        "id": "UopQCgqbeKlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_img_path = \"/content/drive/MyDrive/477_lab_exam/group_distribution.png\"\n",
        "plt.savefig(output_img_path, dpi=300)\n",
        "plt.show()\n",
        "\n",
        "print(f\"✅ Saved group distribution chart as: {output_img_path}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "DuNVrvFPeNCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,6))\n",
        "plt.pie(group_counts.values, labels=[f\"Group {i}\" for i in group_counts.index],\n",
        "        autopct='%1.1f%%', colors=sns.color_palette('pastel'), startangle=90)\n",
        "plt.title(\"Proportion of Comments in Each Group\")\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "output_pie_path = \"/content/drive/MyDrive/477_lab_exam/group_distribution_pie.png\"\n",
        "plt.savefig(output_pie_path, dpi=300)\n",
        "plt.show()\n",
        "\n",
        "print(f\"✅ Saved pie chart as: {output_pie_path}\")"
      ],
      "metadata": {
        "id": "Z54PzTlWePPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/477_lab_exam/grouped_comments_sentiment.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "total_comments = len(df)\n",
        "\n",
        "\n",
        "group_counts = df['Group'].value_counts().sort_index()\n",
        "\n",
        "\n",
        "fail_counts = total_comments - group_counts\n",
        "print(\"Number of comments that FAIL to each group:\")\n",
        "display(fail_counts)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.barplot(x=fail_counts.index, y=fail_counts.values, palette='pastel')\n",
        "\n",
        "\n",
        "for i, count in enumerate(fail_counts.values):\n",
        "    plt.text(i, count + max(fail_counts.values)*0.01, str(count),\n",
        "             ha='center', va='bottom', fontsize=12)\n",
        "\n",
        "plt.title(\"Number of Comments Failing to Each Group\", fontsize=14)\n",
        "plt.xlabel(\"Group\", fontsize=12)\n",
        "plt.ylabel(\"Number of Comments\", fontsize=12)\n",
        "plt.xticks(ticks=[0,1,2], labels=[f\"Group {i}\" for i in fail_counts.index])\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "bar_chart_path = \"/content/drive/MyDrive/477_lab_exam/fail_to_group_bar.png\"\n",
        "plt.savefig(bar_chart_path, dpi=300)\n",
        "plt.show()\n",
        "print(f\"✅ Bar chart saved at: {bar_chart_path}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VnxpefoPekE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,6))\n",
        "plt.pie(fail_counts.values, labels=[f\"Group {i}\" for i in fail_counts.index],\n",
        "        autopct='%1.1f%%', startangle=90, colors=sns.color_palette('pastel'))\n",
        "plt.title(\"Proportion of Comments Failing to Each Group\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save pie chart\n",
        "pie_chart_path = \"/content/drive/MyDrive/477_lab_exam/fail_to_group_pie.png\"\n",
        "plt.savefig(pie_chart_path, dpi=300)\n",
        "plt.show()\n",
        "print(f\"✅ Pie chart saved at: {pie_chart_path}\")"
      ],
      "metadata": {
        "id": "cMzivXOWeztE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}